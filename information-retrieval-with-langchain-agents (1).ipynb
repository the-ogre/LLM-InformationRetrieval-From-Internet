{"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":7241456,"sourceType":"datasetVersion","datasetId":4194267},{"sourceId":7241934,"sourceType":"datasetVersion","datasetId":4194582},{"sourceId":5112,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":3900}],"dockerImageVersionId":30626,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport warnings\nwarnings.filterwarnings('ignore')","metadata":{"execution":{"iopub.status.busy":"2023-12-20T01:27:40.315545Z","iopub.execute_input":"2023-12-20T01:27:40.315949Z","iopub.status.idle":"2023-12-20T01:27:40.686669Z","shell.execute_reply.started":"2023-12-20T01:27:40.315915Z","shell.execute_reply":"2023-12-20T01:27:40.685878Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":"### Making Jupyter Notebook eligible for the code run","metadata":{}},{"cell_type":"code","source":"# !pip install playwright\n# !playwright install","metadata":{"execution":{"iopub.status.busy":"2023-12-20T03:20:10.655381Z","iopub.execute_input":"2023-12-20T03:20:10.656369Z","iopub.status.idle":"2023-12-20T03:20:10.660535Z","shell.execute_reply.started":"2023-12-20T03:20:10.656328Z","shell.execute_reply":"2023-12-20T03:20:10.659603Z"},"trusted":true},"execution_count":130,"outputs":[]},{"cell_type":"markdown","source":"### Installing Dependencies","metadata":{}},{"cell_type":"code","source":"#!pip install torch --index-url https://download.pytorch.org/whl/cu118\n#!pip install langchain tiktoken wikipedia  duckduckgo-search bitsandbytes trl\n#!pip install -q accelerate==0.21.0","metadata":{"execution":{"iopub.status.busy":"2023-12-20T01:33:28.181020Z","iopub.execute_input":"2023-12-20T01:33:28.181409Z","iopub.status.idle":"2023-12-20T01:33:28.185702Z","shell.execute_reply.started":"2023-12-20T01:33:28.181373Z","shell.execute_reply":"2023-12-20T01:33:28.184710Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"print('Successfully installed bitsandbytes-0.41.3.post2 curl-cffi-0.5.10 duckduckgo-search-4.1.0 jsonpatch-1.33 langchain-0.0.351 langchain-community-0.0.4 langchain-core-0.1.1 langsmith-0.0.72 packaging-23.2 shtab-1.6.5 tiktoken-0.5.2 trl-0.7.4 tyro-0.6.0 wikipedia-1.4.0')","metadata":{"execution":{"iopub.status.busy":"2023-12-20T01:29:29.210250Z","iopub.execute_input":"2023-12-20T01:29:29.210691Z","iopub.status.idle":"2023-12-20T01:29:29.217003Z","shell.execute_reply.started":"2023-12-20T01:29:29.210642Z","shell.execute_reply":"2023-12-20T01:29:29.216087Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"Successfully installed bitsandbytes-0.41.3.post2 curl-cffi-0.5.10 duckduckgo-search-4.1.0 jsonpatch-1.33 langchain-0.0.351 langchain-community-0.0.4 langchain-core-0.1.1 langsmith-0.0.72 packaging-23.2 shtab-1.6.5 tiktoken-0.5.2 trl-0.7.4 tyro-0.6.0 wikipedia-1.4.0\n","output_type":"stream"}]},{"cell_type":"code","source":"device='cuda'\n!nvcc --version","metadata":{"execution":{"iopub.status.busy":"2023-12-20T02:56:48.190243Z","iopub.execute_input":"2023-12-20T02:56:48.190664Z","iopub.status.idle":"2023-12-20T02:56:49.210687Z","shell.execute_reply.started":"2023-12-20T02:56:48.190631Z","shell.execute_reply":"2023-12-20T02:56:49.209381Z"},"trusted":true},"execution_count":114,"outputs":[{"name":"stdout","text":"nvcc: NVIDIA (R) Cuda compiler driver\nCopyright (c) 2005-2022 NVIDIA Corporation\nBuilt on Wed_Sep_21_10:33:58_PDT_2022\nCuda compilation tools, release 11.8, V11.8.89\nBuild cuda_11.8.r11.8/compiler.31833905_0\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### Parameters to quantize the model","metadata":{}},{"cell_type":"code","source":"import torch\nimport transformers\nfrom transformers import BitsAndBytesConfig\n\nuse_4bit = True\nbnb_4bit_compute_dtype = \"float16\"\nbnb_4bit_quant_type = \"nf4\"\nuse_nested_quant = True #double quantization\n\ncompute_dtype = getattr(torch, bnb_4bit_compute_dtype)\n\nbnb_config = BitsAndBytesConfig(\n    load_in_4bit=use_4bit,\n    bnb_4bit_quant_type=bnb_4bit_quant_type,\n    bnb_4bit_compute_dtype=compute_dtype,\n    bnb_4bit_use_double_quant=use_nested_quant,\n)","metadata":{"execution":{"iopub.status.busy":"2023-12-20T01:30:46.499756Z","iopub.execute_input":"2023-12-20T01:30:46.500163Z","iopub.status.idle":"2023-12-20T01:30:46.509072Z","shell.execute_reply.started":"2023-12-20T01:30:46.500131Z","shell.execute_reply":"2023-12-20T01:30:46.507941Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":"### Readying the model","metadata":{}},{"cell_type":"code","source":"from transformers import AutoModelForCausalLM\nmodel_name = \"/kaggle/input/mistral/pytorch/7b-instruct-v0.1-hf/1\"\n\nmodel = AutoModelForCausalLM.from_pretrained(\n    model_name, \n    quantization_config = bnb_config, #quantization config file\n    do_sample=True,\n    device_map='auto'\n)","metadata":{"execution":{"iopub.status.busy":"2023-12-20T01:30:49.957607Z","iopub.execute_input":"2023-12-20T01:30:49.958239Z","iopub.status.idle":"2023-12-20T01:33:19.898015Z","shell.execute_reply.started":"2023-12-20T01:30:49.958194Z","shell.execute_reply":"2023-12-20T01:33:19.896938Z"},"trusted":true},"execution_count":7,"outputs":[{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a9c84e36c69748c69011cd6775a5b3a3"}},"metadata":{}}]},{"cell_type":"markdown","source":"### Tokenization","metadata":{}},{"cell_type":"code","source":"from transformers import AutoTokenizer\n\ntokenizer = AutoTokenizer.from_pretrained(model_name,\n                                         add_eos_token=True,\n                                         eos_token_id=2)\ntokenizer.pad_token_id = tokenizer.eos_token_id\ntokenizer.padding_side = \"right\"","metadata":{"execution":{"iopub.status.busy":"2023-12-20T02:29:08.555485Z","iopub.execute_input":"2023-12-20T02:29:08.556483Z","iopub.status.idle":"2023-12-20T02:29:08.652686Z","shell.execute_reply.started":"2023-12-20T02:29:08.556443Z","shell.execute_reply":"2023-12-20T02:29:08.651636Z"},"trusted":true},"execution_count":75,"outputs":[]},{"cell_type":"markdown","source":"### Creating a text generation transformers(HF) pipeline","metadata":{}},{"cell_type":"code","source":"from transformers import pipeline\ntext_generation_pipeline = pipeline(\n    model=model,\n    tokenizer=tokenizer,\n    task=\"text-generation\",\n    temperature=0.1,\n    return_full_text=False,\n    max_new_tokens=200,\n)\n\nfrom langchain.llms import HuggingFacePipeline\nllm = HuggingFacePipeline(pipeline=text_generation_pipeline)","metadata":{"execution":{"iopub.status.busy":"2023-12-20T03:55:09.051532Z","iopub.execute_input":"2023-12-20T03:55:09.051986Z","iopub.status.idle":"2023-12-20T03:55:09.058410Z","shell.execute_reply.started":"2023-12-20T03:55:09.051953Z","shell.execute_reply":"2023-12-20T03:55:09.057287Z"},"trusted":true},"execution_count":153,"outputs":[]},{"cell_type":"markdown","source":"### Instantiating the langchain utilities","metadata":{}},{"cell_type":"code","source":"from langchain.utilities import WikipediaAPIWrapper\nwikipedia = WikipediaAPIWrapper(top_k_results=1, lang='en', load_all_available_meta=False, doc_content_chars_max=800)\n\nfrom langchain.tools import DuckDuckGoSearchRun\nsearch = DuckDuckGoSearchRun()","metadata":{"execution":{"iopub.status.busy":"2023-12-20T04:42:17.806957Z","iopub.execute_input":"2023-12-20T04:42:17.807846Z","iopub.status.idle":"2023-12-20T04:42:17.813613Z","shell.execute_reply.started":"2023-12-20T04:42:17.807808Z","shell.execute_reply":"2023-12-20T04:42:17.812470Z"},"trusted":true},"execution_count":185,"outputs":[]},{"cell_type":"markdown","source":"### Instantiating the langchain tools","metadata":{}},{"cell_type":"code","source":"from langchain.agents import Tool \ntools = []\n\nwikipedia_tool = Tool(    \n    name=\"wikipedia\",    \n    func=wikipedia.run,    \n    description=\"wikipedia tool\" )\n\nduckduckgo_tool = Tool(    \n    name=\"search\",    \n    func=search.run,    \n    description=\"web search tool\")\n\ntools.append(wikipedia_tool)\ntools.append(duckduckgo_tool) ","metadata":{"execution":{"iopub.status.busy":"2023-12-20T04:42:22.888756Z","iopub.execute_input":"2023-12-20T04:42:22.889142Z","iopub.status.idle":"2023-12-20T04:42:22.895126Z","shell.execute_reply.started":"2023-12-20T04:42:22.889111Z","shell.execute_reply":"2023-12-20T04:42:22.894042Z"},"trusted":true},"execution_count":186,"outputs":[]},{"cell_type":"code","source":"print(tools)","metadata":{"execution":{"iopub.status.busy":"2023-12-20T04:42:28.160973Z","iopub.execute_input":"2023-12-20T04:42:28.161998Z","iopub.status.idle":"2023-12-20T04:42:28.166830Z","shell.execute_reply.started":"2023-12-20T04:42:28.161956Z","shell.execute_reply":"2023-12-20T04:42:28.165870Z"},"trusted":true},"execution_count":187,"outputs":[{"name":"stdout","text":"[Tool(name='wikipedia', description='wikipedia search tool', func=<bound method WikipediaAPIWrapper.run of WikipediaAPIWrapper(wiki_client=<module 'wikipedia' from '/opt/conda/lib/python3.10/site-packages/wikipedia/__init__.py'>, top_k_results=1, lang='en', load_all_available_meta=False, doc_content_chars_max=800)>), Tool(name='search', description='web search tool', func=<bound method BaseTool.run of DuckDuckGoSearchRun()>)]\n","output_type":"stream"}]},{"cell_type":"code","source":"duckduckgo_tool?","metadata":{"execution":{"iopub.status.busy":"2023-12-20T04:42:45.603433Z","iopub.execute_input":"2023-12-20T04:42:45.603858Z","iopub.status.idle":"2023-12-20T04:42:45.611337Z","shell.execute_reply.started":"2023-12-20T04:42:45.603824Z","shell.execute_reply":"2023-12-20T04:42:45.610280Z"},"trusted":true},"execution_count":188,"outputs":[{"output_type":"display_data","data":{"text/plain":"\u001b[0;31mSignature:\u001b[0m      \u001b[0mduckduckgo_tool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtool_input\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'str'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'Callbacks'\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;34m'str'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;31mType:\u001b[0m           Tool\n\u001b[0;31mString form:\u001b[0m    name='search' description='web search tool' func=<bound method BaseTool.run of DuckDuckGoSearchRun()>\n\u001b[0;31mFile:\u001b[0m           /opt/conda/lib/python3.10/site-packages/langchain_core/tools.py\n\u001b[0;31mDocstring:\u001b[0m      Tool that takes in function or coroutine directly.\n\u001b[0;31mInit docstring:\u001b[0m Initialize tool.\n\u001b[0;31mCall docstring:\u001b[0m Make tool callable."},"metadata":{}}]},{"cell_type":"markdown","source":"### Initializaing the Agent for zero shot Retrieval Action Chain","metadata":{}},{"cell_type":"code","source":"from langchain.agents import initialize_agent \n\n\nN=3\nzero_shot_agent = initialize_agent(   \n    tools=tools,    \n    llm=llm,    \n    verbose=True,    \n    max_interations=2, \n    handle_parsing_errors=True\n)","metadata":{"execution":{"iopub.status.busy":"2023-12-20T04:47:39.504919Z","iopub.execute_input":"2023-12-20T04:47:39.505722Z","iopub.status.idle":"2023-12-20T04:47:39.511305Z","shell.execute_reply.started":"2023-12-20T04:47:39.505680Z","shell.execute_reply":"2023-12-20T04:47:39.510276Z"},"trusted":true},"execution_count":193,"outputs":[]},{"cell_type":"code","source":"initialize_agent?","metadata":{"execution":{"iopub.status.busy":"2023-12-20T04:47:42.200843Z","iopub.execute_input":"2023-12-20T04:47:42.201742Z","iopub.status.idle":"2023-12-20T04:47:42.211444Z","shell.execute_reply.started":"2023-12-20T04:47:42.201707Z","shell.execute_reply":"2023-12-20T04:47:42.210411Z"},"trusted":true},"execution_count":194,"outputs":[{"output_type":"display_data","data":{"text/plain":"\u001b[0;31mSignature:\u001b[0m\n\u001b[0minitialize_agent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m    \u001b[0mtools\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mSequence\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlangchain_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBaseTool\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m    \u001b[0mllm\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlangchain_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlanguage_models\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBaseLanguageModel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m    \u001b[0magent\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlangchain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0magents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0magent_types\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAgentType\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m    \u001b[0mcallback_manager\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlangchain_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBaseCallbackManager\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m    \u001b[0magent_path\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m    \u001b[0magent_kwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m    \u001b[0;34m*\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m    \u001b[0mtags\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mSequence\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m    \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mlangchain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0magents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAgentExecutor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;31mDocstring:\u001b[0m\nLoad an agent executor given tools and LLM.\n\nArgs:\n    tools: List of tools this agent has access to.\n    llm: Language model to use as the agent.\n    agent: Agent type to use. If None and agent_path is also None, will default to\n        AgentType.ZERO_SHOT_REACT_DESCRIPTION.\n    callback_manager: CallbackManager to use. Global callback manager is used if\n        not provided. Defaults to None.\n    agent_path: Path to serialized agent to use.\n    agent_kwargs: Additional keyword arguments to pass to the underlying agent\n    tags: Tags to apply to the traced runs.\n    **kwargs: Additional keyword arguments passed to the agent executor\n\nReturns:\n    An agent executor\n\u001b[0;31mFile:\u001b[0m      /opt/conda/lib/python3.10/site-packages/langchain/agents/initialize.py\n\u001b[0;31mType:\u001b[0m      function"},"metadata":{}}]},{"cell_type":"code","source":"print(zero_shot_agent)","metadata":{"execution":{"iopub.status.busy":"2023-12-20T04:47:52.247556Z","iopub.execute_input":"2023-12-20T04:47:52.248004Z","iopub.status.idle":"2023-12-20T04:47:52.254031Z","shell.execute_reply.started":"2023-12-20T04:47:52.247971Z","shell.execute_reply":"2023-12-20T04:47:52.253004Z"},"trusted":true},"execution_count":195,"outputs":[{"name":"stdout","text":"verbose=True tags=['zero-shot-react-description'] agent=ZeroShotAgent(llm_chain=LLMChain(prompt=PromptTemplate(input_variables=['agent_scratchpad', 'input'], template='Answer the following questions as best you can. You have access to the following tools:\\n\\nwikipedia: wikipedia search tool\\nsearch: web search tool\\n\\nUse the following format:\\n\\nQuestion: the input question you must answer\\nThought: you should always think about what to do\\nAction: the action to take, should be one of [wikipedia, search]\\nAction Input: the input to the action\\nObservation: the result of the action\\n... (this Thought/Action/Action Input/Observation can repeat N times)\\nThought: I now know the final answer\\nFinal Answer: the final answer to the original input question\\n\\nBegin!\\n\\nQuestion: {input}\\nThought:{agent_scratchpad}'), llm=HuggingFacePipeline(pipeline=<transformers.pipelines.text_generation.TextGenerationPipeline object at 0x78c6091077f0>)), output_parser=MRKLOutputParser(), allowed_tools=['wikipedia', 'search']) tools=[Tool(name='wikipedia', description='wikipedia search tool', func=<bound method WikipediaAPIWrapper.run of WikipediaAPIWrapper(wiki_client=<module 'wikipedia' from '/opt/conda/lib/python3.10/site-packages/wikipedia/__init__.py'>, top_k_results=1, lang='en', load_all_available_meta=False, doc_content_chars_max=800)>), Tool(name='search', description='web search tool', func=<bound method BaseTool.run of DuckDuckGoSearchRun()>)] handle_parsing_errors=True\n","output_type":"stream"}]},{"cell_type":"code","source":"zero_shot_agent.run?","metadata":{"execution":{"iopub.status.busy":"2023-12-20T04:48:16.281175Z","iopub.execute_input":"2023-12-20T04:48:16.281978Z","iopub.status.idle":"2023-12-20T04:48:16.293113Z","shell.execute_reply.started":"2023-12-20T04:48:16.281940Z","shell.execute_reply":"2023-12-20T04:48:16.292083Z"},"trusted":true},"execution_count":196,"outputs":[{"output_type":"display_data","data":{"text/plain":"\u001b[0;31mSignature:\u001b[0m\n\u001b[0mzero_shot_agent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m    \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m    \u001b[0mcallbacks\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlangchain_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBaseCallbackHandler\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlangchain_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBaseCallbackManager\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNoneType\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m    \u001b[0mtags\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m    \u001b[0mmetadata\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mDict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m    \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;31mDocstring:\u001b[0m\nConvenience method for executing chain.\n\nThe main difference between this method and `Chain.__call__` is that this\nmethod expects inputs to be passed directly in as positional arguments or\nkeyword arguments, whereas `Chain.__call__` expects a single input dictionary\nwith all the inputs\n\nArgs:\n    *args: If the chain expects a single input, it can be passed in as the\n        sole positional argument.\n    callbacks: Callbacks to use for this chain run. These will be called in\n        addition to callbacks passed to the chain during construction, but only\n        these runtime callbacks will propagate to calls to other objects.\n    tags: List of string tags to pass to all callbacks. These will be passed in\n        addition to tags passed to the chain during construction, but only\n        these runtime tags will propagate to calls to other objects.\n    **kwargs: If the chain expects multiple inputs, they can be passed in\n        directly as keyword arguments.\n\nReturns:\n    The chain output.\n\nExample:\n    .. code-block:: python\n\n        # Suppose we have a single-input chain that takes a 'question' string:\n        chain.run(\"What's the temperature in Boise, Idaho?\")\n        # -> \"The temperature in Boise is...\"\n\n        # Suppose we have a multi-input chain that takes a 'question' string\n        # and 'context' string:\n        question = \"What's the temperature in Boise, Idaho?\"\n        context = \"Weather report for Boise, Idaho on 07/03/23...\"\n        chain.run(question=question, context=context)\n        # -> \"The temperature in Boise is...\"\n\u001b[0;31mFile:\u001b[0m      /opt/conda/lib/python3.10/site-packages/langchain/chains/base.py\n\u001b[0;31mType:\u001b[0m      method"},"metadata":{}}]},{"cell_type":"markdown","source":"### Examples","metadata":{}},{"cell_type":"code","source":"product='SageMaker'","metadata":{"execution":{"iopub.status.busy":"2023-12-20T04:48:19.868658Z","iopub.execute_input":"2023-12-20T04:48:19.869626Z","iopub.status.idle":"2023-12-20T04:48:19.873888Z","shell.execute_reply.started":"2023-12-20T04:48:19.869577Z","shell.execute_reply":"2023-12-20T04:48:19.872803Z"},"trusted":true},"execution_count":197,"outputs":[]},{"cell_type":"code","source":"zero_shot_agent.run(product)","metadata":{"execution":{"iopub.status.busy":"2023-12-20T04:48:22.218853Z","iopub.execute_input":"2023-12-20T04:48:22.219254Z","iopub.status.idle":"2023-12-20T04:49:19.399263Z","shell.execute_reply.started":"2023-12-20T04:48:22.219210Z","shell.execute_reply":"2023-12-20T04:49:19.398225Z"},"trusted":true},"execution_count":198,"outputs":[{"name":"stderr","text":"Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"\n\n\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n\u001b[32;1m\u001b[1;3m I should use the wikipedia search tool to find out more about SageMaker\nAction: wikipedia\nAction Input: SageMaker\u001b[0m","output_type":"stream"},{"name":"stderr","text":"Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"\nObservation: \u001b[36;1m\u001b[1;3mPage: Amazon SageMaker\nSummary: Amazon SageMaker is a cloud based machine-learning platform that allows the creation, training, and deployment by developers of machine-learning (ML) models on the cloud. It can be used to deploy ML models on embedded systems and edge-devices. SageMaker was launched in November 2017.\u001b[0m\nThought:\u001b[32;1m\u001b[1;3m I should use the wikipedia search tool to find out more about SageMaker\nAction: wikipedia\nAction Input: SageMaker\u001b[0m","output_type":"stream"},{"name":"stderr","text":"Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"\nObservation: \u001b[36;1m\u001b[1;3mPage: Amazon SageMaker\nSummary: Amazon SageMaker is a cloud based machine-learning platform that allows the creation, training, and deployment by developers of machine-learning (ML) models on the cloud. It can be used to deploy ML models on embedded systems and edge-devices. SageMaker was launched in November 2017.\u001b[0m\nThought:\u001b[32;1m\u001b[1;3m I should use the web search tool to find out more about SageMaker\nAction: search\nAction Input: SageMaker\u001b[0m","output_type":"stream"},{"name":"stderr","text":"Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"\nObservation: \u001b[33;1m\u001b[1;3mAmazon SageMaker Feature Store is a fully managed, purpose-built repository to store, share, and manage features for machine learning (ML) models. Features are inputs to ML models used during training and inference. For example, in an application that recommends a music playlist, features could include song ratings, listening duration, and ... SageMaker HyperPod accelerates FM training at scale: Many organizations want to train their own models using graphics processing units (GPU)-based and Trainium-based compute instances at low cost. However, the volume of data, size of the models, and time required for training models has exponentially increased the complexity of training a model ... The SageMaker Studio UI enables you to access and discover SageMaker resources and ML tooling such as Jobs, Endpoints, and Pipelines in a consistent manner, regardless of your IDE of choice. SageMaker Studio contains a default private space that only you can access and run in JupyterLab or Code Editor. You also have the option to create a new ... For SageMaker hosting instance, choose your instance (for this post, we use ml.g5.2xlarge). For Endpoint name, enter demo-stabilityai-stable-diffusion-v2. Choose Deploy. Because this is a larger model, it can take up to 25 minutes to deploy. When it's ready, the endpoint status shows as In Service. Today, we are announcing an improved Amazon SageMaker Studio experience! The new SageMaker Studio web-based interface loads faster and provides consistent access to your preferred integrated development environment (IDE) and SageMaker resources and tooling, irrespective of your IDE choice. In addition to JupyterLab and RStudio, SageMaker Studio now includes a fully managed Code Editor based [â€¦]\u001b[0m\nThought:\u001b[32;1m\u001b[1;3m I now know the final answer\nFinal Answer: Amazon SageMaker is a cloud based machine-learning platform that allows the creation, training, and deployment by developers of machine-learning (ML) models on the cloud. It can be used to deploy ML models on embedded systems and edge-devices. SageMaker was launched in November 2017. It has many features such as Amazon SageMaker Feature Store, SageMaker HyperPod accelerates FM training at scale, and SageMaker Studio UI.\u001b[0m\n\n\u001b[1m> Finished chain.\u001b[0m\n","output_type":"stream"},{"execution_count":198,"output_type":"execute_result","data":{"text/plain":"'Amazon SageMaker is a cloud based machine-learning platform that allows the creation, training, and deployment by developers of machine-learning (ML) models on the cloud. It can be used to deploy ML models on embedded systems and edge-devices. SageMaker was launched in November 2017. It has many features such as Amazon SageMaker Feature Store, SageMaker HyperPod accelerates FM training at scale, and SageMaker Studio UI.'"},"metadata":{}}]},{"cell_type":"markdown","source":"### Examples","metadata":{}},{"cell_type":"code","source":"import time","metadata":{"execution":{"iopub.status.busy":"2023-12-20T04:49:44.574363Z","iopub.execute_input":"2023-12-20T04:49:44.575108Z","iopub.status.idle":"2023-12-20T04:49:44.579255Z","shell.execute_reply.started":"2023-12-20T04:49:44.575070Z","shell.execute_reply":"2023-12-20T04:49:44.578330Z"},"trusted":true},"execution_count":199,"outputs":[]},{"cell_type":"code","source":"product2 = 'AWS lambda'","metadata":{"execution":{"iopub.status.busy":"2023-12-20T04:54:54.833432Z","iopub.execute_input":"2023-12-20T04:54:54.833846Z","iopub.status.idle":"2023-12-20T04:54:54.838307Z","shell.execute_reply.started":"2023-12-20T04:54:54.833811Z","shell.execute_reply":"2023-12-20T04:54:54.837435Z"},"trusted":true},"execution_count":205,"outputs":[]},{"cell_type":"code","source":"def generate_description(product):\n    start_time = time.time()\n    description = zero_shot_agent.run(f\"Fetch basic information on {product}. \\\n    and write an introductory three-line description on it.\")\n    print(description)\n    end_time = time.time()\n    print(f'\\nTime Taken= {end_time - start_time}')\n    return description","metadata":{"execution":{"iopub.status.busy":"2023-12-20T05:05:16.214556Z","iopub.status.idle":"2023-12-20T05:05:16.214984Z","shell.execute_reply.started":"2023-12-20T05:05:16.214787Z","shell.execute_reply":"2023-12-20T05:05:16.214804Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"generate_description(product2)","metadata":{"execution":{"iopub.status.busy":"2023-12-20T05:05:32.024834Z","iopub.execute_input":"2023-12-20T05:05:32.025239Z","iopub.status.idle":"2023-12-20T05:06:14.335610Z","shell.execute_reply.started":"2023-12-20T05:05:32.025199Z","shell.execute_reply":"2023-12-20T05:06:14.334611Z"},"trusted":true},"execution_count":209,"outputs":[{"name":"stderr","text":"Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"\n\n\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n\u001b[32;1m\u001b[1;3m I should start by searching for the software on wikipedia.\nAction: wikipedia\nAction Input: AWS lambda\u001b[0m","output_type":"stream"},{"name":"stderr","text":"Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"\nObservation: \u001b[36;1m\u001b[1;3mPage: AWS Lambda\nSummary: AWS Lambda is an event-driven, serverless computing platform provided by Amazon as a part of Amazon Web Services. It is designed to enable developers to run code without provisioning or managing servers. It executes code in response to events and automatically manages the computing resources required by that code. It was introduced on November 13, 2014.Node.js, Python, Java, Go, Ruby, and C# (through .NET) are all officially supported as of 2018. In late 2018, custom runtime support was added to AWS Lambda.\nAWS Lambda supports running native Linux executables by calling them from a supported runtime, such as Node.js. For example, Haskell code can be run on Lambda.AWS Lambda was primarily designed for tasks such as handling image and object uploads to Amazon S3, up\u001b[0m\nThought:\u001b[32;1m\u001b[1;3m I should also search for the software on the web.\nAction: search\nAction Input: AWS lambda\u001b[0m","output_type":"stream"},{"name":"stderr","text":"Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"\nObservation: \u001b[33;1m\u001b[1;3mAWS Lambda Last updated September 27, 2023 Implementation Enter the Lambda console Select a Lambda blueprint and configure it Review Lambda settings Invoke Lambda function and verify results Monitor your metrics Delete the Lambda function Conclusion Congratulations! You have created your first AWS Lambda function. Learn how to use AWS Lambda, a serverless computing platform that executes your code based on events from AWS services. See how to upload code, trigger events, use concepts, compare with AWS EC2 and Elastic Beanstalk, and explore use cases and best practices of AWS Lambda function. AWS Lambda is an event-driven computing service that runs code and manages the underlying resources automatically. It supports different programming languages, triggers, and integrations with other AWS services. Learn what AWS Lambda is, how it works, its features, pricing, and examples. AWS Lambda is a compute service that runs your code in response to events and automatically manages the computing resources required by that code. Lambda can run code written in Node.js, Python, Java, Go, Ruby, C#, and PowerShell. It can also be used with other AWS services such as Amazon S3, Amazon DynamoDB, and Amazon API Gateway. ... AWS Lambda now supports Amazon Linux 2023 (AL2023) as a managed runtime and container base image. Named provided.al2023, this runtime provides an OS-only environment to run your Lambda functions. It is based on the Amazon Linux 2023 minimal container image release and has several improvements over Amazon Linux 2 (AL2), such as a smaller ...\u001b[0m\nThought:\u001b[32;1m\u001b[1;3m I should now know the final answer.\nFinal Answer: AWS Lambda is an event-driven, serverless computing platform provided by Amazon as a part of Amazon Web Services. It is designed to enable developers to run code without provisioning or managing servers. It executes code in response to events and automatically manages the computing resources required by that code. It supports different programming languages, triggers, and integrations with other AWS services. AWS Lambda now supports Amazon Linux 2023 (AL2023) as a managed runtime and container base image.\u001b[0m\n\n\u001b[1m> Finished chain.\u001b[0m\nAWS Lambda is an event-driven, serverless computing platform provided by Amazon as a part of Amazon Web Services. It is designed to enable developers to run code without provisioning or managing servers. It executes code in response to events and automatically manages the computing resources required by that code. It supports different programming languages, triggers, and integrations with other AWS services. AWS Lambda now supports Amazon Linux 2023 (AL2023) as a managed runtime and container base image.\n\nTime Taken= 42.304484605789185\n","output_type":"stream"},{"execution_count":209,"output_type":"execute_result","data":{"text/plain":"'AWS Lambda is an event-driven, serverless computing platform provided by Amazon as a part of Amazon Web Services. It is designed to enable developers to run code without provisioning or managing servers. It executes code in response to events and automatically manages the computing resources required by that code. It supports different programming languages, triggers, and integrations with other AWS services. AWS Lambda now supports Amazon Linux 2023 (AL2023) as a managed runtime and container base image.'"},"metadata":{}}]},{"cell_type":"markdown","source":"### Final Comments\n\n- The above code is not full proof. The tools and agents developed by LangChain are not full proof. As of 20/12/23, they seem to be mostly in development phase. \n- I ran the code on Kaggle. But using paid GPUs of collab would have given my the functionality of working in a browser. The Retrival Tools needs to fetch data from external websites. And it seems after some time, they forget access.\n- I could haveused Google Search API from langchain as well, but it is paid. \n- But the code is a good exmaple of two things:\n    - One, langchain is not full proof developer ready. We depend too much on the prompts already generated for us.\n    - The workflow of a typical LLM based search query is easily visible in this code.","metadata":{}}]}